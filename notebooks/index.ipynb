{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Marketing Prediction - Google Colab Notebook\n",
    "\n",
    "This notebook replicates the bank marketing prediction project in a Google Colab environment.\n",
    "\n",
    "**Workflow:**\n",
    "1. **Setup Environment**: Mount Google Drive and install necessary Python libraries.\n",
    "2. **Prepare Directories & Imports**: Import all libraries and create output directories.\n",
    "3. **Define Preprocessing Functions**: Define functions to load and prepare the data.\n",
    "4. **Define Model Training Function**: Define the main function for training, tuning, and evaluating the models.\n",
    "5. **Run Main Pipeline**: Execute the entire workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup Environment\n",
    "\n",
    "Mount Google Drive to access the dataset and install the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive to access the dataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install required libraries\n",
    "!pip install pandas scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare Directories & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Create output directories in the Colab environment\n",
    "output_dir = 'outputs'\n",
    "cm_dir = os.path.join(output_dir, 'confusion-matrix')\n",
    "scorer_dir = os.path.join(output_dir, 'scorer')\n",
    "\n",
    "os.makedirs(cm_dir, exist_ok=True)\n",
    "os.makedirs(scorer_dir, exist_ok=True)\n",
    "\n",
    "split_ratios_for_dir = [0.7, 0.8, 0.9]\n",
    "for ratio in split_ratios_for_dir:\n",
    "    split_str = str(ratio).replace('.', '_')\n",
    "    os.makedirs(os.path.join(scorer_dir, f'splits_{int(ratio*100)}_{100-int(ratio*100)}'), exist_ok=True)\n",
    "\n",
    "print(\"Directories created successfully in the Colab environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Loads data from a CSV file.\"\"\"\n",
    "    return pd.read_csv(file_path, sep=';')\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Encodes categorical features and scales numerical features.\"\"\"\n",
    "    # Encode categorical features\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_features:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "    # Scaling numerical features\n",
    "    # Exclude the target variable 'y' from scaling\n",
    "    numerical_features = df.select_dtypes(include=np.number).columns.drop('y')\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, X_test, y_train, y_test, split_ratio, k_fold_cv):\n",
    "    \"\"\"\n",
    "    Trains and evaluates KNN, Decision Tree, and Naive Bayes models.\n",
    "    Performs hyperparameter tuning for KNN.\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        'knn': KNeighborsClassifier(),\n",
    "        'decision_tree': DecisionTreeClassifier(random_state=42),\n",
    "        'naive_bayes': GaussianNB()\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    # Define the parameter grid for KNN\n",
    "    param_grid_knn = {'n_neighbors': list(range(1, 21))}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"--- Running {model_name} with split {split_ratio} and k-fold {k_fold_cv} ---\")\n",
    "        \n",
    "        # Hyperparameter tuning for KNN\n",
    "        if model_name == 'knn':\n",
    "            grid_search = GridSearchCV(model, param_grid_knn, cv=k_fold_cv, scoring='accuracy', n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            print(f\"Best KNN params: {grid_search.best_params_}\")\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            best_model = model\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        # K-fold cross-validation\n",
    "        cv_scores = cross_val_score(best_model, X_train, y_train, cv=k_fold_cv, scoring='accuracy')\n",
    "        mean_cv_accuracy = np.mean(cv_scores)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix: {model_name.replace(\"_\", \" \").title()} (Split {split_ratio})')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        split_str = str(split_ratio).replace('.', '_')\n",
    "        cm_filename = f'{model_name}_split_{split_str}.png'\n",
    "        plt.savefig(os.path.join(cm_dir, cm_filename))\n",
    "        plt.close()\n",
    "\n",
    "        results[model_name] = {\n",
    "            'Split Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'Mean CV Accuracy': mean_cv_accuracy\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_colab():\n",
    "    # Define the dataset path in Google Drive\n",
    "    file_path = '/content/drive/My Drive/Colab Notebooks/bank-marketing-ml/datasets/bank-full.csv'\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"ERROR: Dataset not found at {file_path}\")\n",
    "        print(\"Please make sure the dataset is uploaded to the correct Google Drive path.\")\n",
    "        return\n",
    "\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    df = load_data(file_path)\n",
    "    df_processed = preprocess_data(df.copy())\n",
    "\n",
    "    X = df_processed.drop('y', axis=1)\n",
    "    y = df_processed['y']\n",
    "\n",
    "    split_ratios = [0.7, 0.8, 0.9]\n",
    "    k_folds = [5, 10]\n",
    "    summary_results = []\n",
    "\n",
    "    for ratio in split_ratios:\n",
    "        print(f\"\\n{'='*20} PROCESSING SPLIT RATIO: {int(ratio*100)}/{100-int(ratio*100)} {'='*20}\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-ratio, random_state=42, stratify=y)\n",
    "        \n",
    "        for k_fold in k_folds:\n",
    "            results = train_and_evaluate(X_train, X_test, y_train, y_test, ratio, k_fold)\n",
    "            \n",
    "            for model_name, metrics in results.items():\n",
    "                summary_results.append({\n",
    "                    'Model': model_name,\n",
    "                    'Split Ratio': ratio,\n",
    "                    'K-Fold': k_fold,\n",
    "                    'Split Accuracy': metrics['Split Accuracy'],\n",
    "                    'Mean CV Accuracy': metrics['Mean CV Accuracy']\n",
    "                })\n",
    "                \n",
    "                # Save individual scorer metrics\n",
    "                split_str_dir = f\"splits_{int(ratio*100)}_{100-int(ratio*100)}\"\n",
    "                scorer_path = os.path.join(scorer_dir, split_str_dir)\n",
    "                metric_df = pd.DataFrame([metrics], index=[model_name])\n",
    "                metric_df.to_csv(os.path.join(scorer_path, f'{model_name}_metrics.csv'))\n",
    "\n",
    "\n",
    "    # Create and save summary dataframe\n",
    "    summary_df = pd.DataFrame(summary_results)\n",
    "    summary_df.to_csv(os.path.join(scorer_dir, 'summary_results.csv'), index=False)\n",
    "    print(\"\\nSummary of all runs:\")\n",
    "    print(summary_df)\n",
    "\n",
    "    # Plotting summary results\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(data=summary_df, x='Model', y='Split Accuracy', hue='Split Ratio')\n",
    "    plt.title('Split Accuracy for all Models and Split Ratios')\n",
    "    plt.savefig(os.path.join(scorer_dir, 'split_accuracy_comparison.png'))\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(data=summary_df, x='Model', y='Mean CV Accuracy', hue='K-Fold')\n",
    "    plt.title('Mean CV Accuracy for all Models and K-Folds')\n",
    "    plt.savefig(os.path.join(scorer_dir, 'mean_cv_accuracy_comparison.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nProcessing complete. All outputs saved in the 'outputs' directory in the Colab environment.\")\n",
    "    print(\"You can download the 'outputs' folder from the file browser on the left.\")\n",
    "\n",
    "# Run the main function\n",
    "main_colab()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
